---
title: "Data Prep for Luxrug DB"
subtitle: ""
format: 
  html:
    self-contained: true
author:
- Jiashen Wang
---
```{r, echo=FALSE}
# setup
library(knitr)
library(dplyr)
library(tidyr)
library(stringr)
```


```{r, echo = F}
# SKU
sku = read.csv("raw/LUXRUG - 产品SKU对应表 - 产品包装参数.csv", header = T)
sku_cols = c("产品名称", "公司SKU", "ASIN")
sku = sku[2:nrow(sku),sku_cols]
colnames(sku) = c("name", "sku", "asin")

# extract name of pattern
sku <- sku %>%
  mutate(name = sub("(\\D+).*", "\\1", name))

# extract pattern, size, color
sku <- sku |>
  mutate(size = regmatches(sku, regexpr("[0-9]x[0-9]+", sku)),
         pattern = regmatches(sku, regexpr("[A-Z]\\d+", sku)),
         color = regmatches(sku, regexpr("[A-Z][a-z]+ ?[A-Z]?[a-z]+", sku)))

sku
write.csv(sku, "sku.csv", row.names = FALSE)
```


```{r, echo=FALSE}
# orders
orders <- read.delim("raw/所有订单.txt")

# only retain Amazon orders that are not cancelled and in the US
orders = orders[orders$order.status != "Cancelled" & 
                  orders$sales.channel == "Amazon.com",]

orders_cols = c("amazon.order.id", "purchase.date", "order.status", 
                "asin", "quantity", "item.price", "item.promotion.discount", 
                "ship.city", "ship.state", "ship.postal.code")
orders = orders[,orders_cols]
colnames(orders) = c("order_id", "date", "status", "asin", "quantity", 
                  "price", "discount", "city", "state", "zip")

# format date
orders <- orders |>
  mutate(date = as.POSIXct(date, format="%Y-%m-%dT%H:%M:%S", tz="UTC"))
# only keey 5 digits of zip code
orders$zip <- sub("(\\d{5}).*", "\\1", orders$zip)
# change na's in discount to 0
orders$discount[is.na(orders$discount)] <- 0

orders
write.csv(orders, "orders.csv", row.names = FALSE)
```


```{r, echo=FALSE}
# returns
returns <- read.delim("raw/退货.txt")
returns_cols = c("return.date", "order.id","asin", "detailed.disposition", 
                "reason", "customer.comments")
returns = returns[,returns_cols]
colnames(returns) = c("date", "order_id", "asin", "disposition", 
                  "reason", "comments")

# format date
returns <- returns |>
  mutate(date = as.POSIXct(date, format="%Y-%m-%dT%H:%M:%S", tz="UTC"))


returns
write.csv(returns, "returns.csv", row.names = FALSE)
```


```{r, echo=FALSE}
# sales
sales <- read.csv("raw/业务报告.csv", header = T)
sales_cols = c("X.父.ASIN", "X.子.ASIN", "会话数...总计", "已订购商品数量", "已订购商品销售额")
sales = sales[,sales_cols]
colnames(sales) = c("parent_asin", "asin", "sessions", "n_sold", "revenue")

# sort sales by parent_asin
sales <- sales %>% arrange(desc(parent_asin))
# convert sessions to int
sales$sessions = as.integer(gsub(",", "", sales$sessions))
# convert revenue to dbl
sales$revenue <- as.numeric(gsub(",", "", gsub("US\\$", "", sales$revenue)))

sales
write.csv(sales, "sales.csv", row.names = FALSE)
```


```{r, echo=FALSE}
# reviews
reviews <- read.csv("reviews.csv", header = T)

# remove empty rows
reviews <- reviews[!is.na(reviews$rating), ]
# format date
reviews$date <- as.Date(reviews$date, format = "%m-%d-%Y")

reviews
write.csv(reviews, "reviews.csv", row.names = FALSE)
```


```{r, echo=FALSE}
# # orders
# today <- read.delim("75641020152.txt")
# 
# # only retain Amazon orders that are not cancelled and in the US
# today = today[today$order.status != "Cancelled" & 
#                   today$sales.channel == "Amazon.com",]
# 
# orders_cols = c("amazon.order.id", "purchase.date", "order.status", 
#                 "asin", "quantity", "item.price", "item.promotion.discount", 
#                 "ship.city", "ship.state", "ship.postal.code")
# today = today[,orders_cols]
# colnames(today) = c("order_id", "date", "status", "asin", "quantity", 
#                   "price", "discount", "city", "state", "zip")
# 
# # format date
# today <- today |>
#   mutate(date = as.POSIXct(date, format="%Y-%m-%dT%H:%M:%S", tz="UTC"))
# # only keey 5 digits of zip code
# today$zip <- sub("(\\d{5}).*", "\\1", today$zip)
# # change na's in discount to 0
# today$discount[is.na(today$discount)] <- 0
# 
# today
# write.csv(today, "today.csv", row.names = FALSE)
```